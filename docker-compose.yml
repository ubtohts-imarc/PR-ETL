x-common-env: &common-env
  AIRFLOW__CORE__EXECUTOR: LocalExecutor
  AIRFLOW__CORE__FERNET_KEY: ''
  AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
  AIRFLOW__CORE__DAG_DISCOVERY_SAFE_MODE: 'false'
  PYTHONPATH: /opt/airflow/etl_pipeline
  AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/etl_pipeline/airflow/dags

services:
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.etl
    container_name: airflow_web
    ports:
      - "8080:8080"
    environment:
      <<: *common-env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DATABASE_URL}
      PYTHONPATH : /opt/airflow
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.etl
    container_name: airflow_scheduler
    depends_on:
      - airflow-webserver
      - airflow-init
    environment:
      <<: *common-env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DATABASE_URL}
      PYTHONPATH : /opt/airflow
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.etl
    container_name: airflow_init
    environment:
      <<: *common-env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DATABASE_URL}
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins
        airflow db migrate
        airflow users create \
          --username "$AIRFLOW_USERNAME" \
          --firstname "$AIRFLOW_FIRSTNAME" \
          --lastname "$AIRFLOW_LASTNAME" \
          --role Admin \
          --email "$AIRFLOW_EMAIL" \
          --password "$AIRFLOW_PASSWORD"
    restart: on-failure

  alembic-migration:
    build:
      context: .
      dockerfile: Dockerfile.etl
    container_name: alembic_migration
    working_dir: /opt/airflow/db
    environment:
      - PR_DATABASE_URL=${PR_DATABASE_URL}
      - PYTHONPATH=/opt/airflow
    entrypoint: /bin/bash
    command:
      - -c
      - |
        echo "Running Alembic Migration..."
        alembic revision --autogenerate -m "Auto migration"
        alembic upgrade head
    restart: on-failure

  redis:
    image: redis:6
    container_name: redis_service
    restart: always
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  api-server:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: fastapi_server
    ports:
      - "8000:8000"
    environment:
      - PR_DATABASE_URL=${PR_DATABASE_URL}
      - PYTHONPATH=/app
    restart: always

volumes:
  postgres-db-volume: